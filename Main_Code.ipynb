{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating All Dataframes (5 Minutes to Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/d69xwzdn6q73cqq4lfn917km0000gn/T/ipykernel_21633/2146027499.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_titles = pd.read_csv('title.basics.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "# creating all dataframes\n",
    "\n",
    "df_titles = pd.read_csv('title.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals = pd.read_csv('title.principals.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors = pd.read_csv('name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/d69xwzdn6q73cqq4lfn917km0000gn/T/ipykernel_21633/372025501.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_titles_clean_2['startYear'] = pd.to_numeric(df_titles_clean_2['startYear'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# cleaning df_titles\n",
    "\n",
    "df_titles_clean = df_titles.copy()\n",
    "\n",
    "# remove everything but movies\n",
    "df_titles_clean_0 = df_titles_clean[df_titles_clean['titleType'] == 'movie']\n",
    "\n",
    "# remove adult titles\n",
    "df_titles_clean_1 = df_titles_clean_0[df_titles_clean_0['isAdult'] != 1]\n",
    "\n",
    "# remove start year being '\\N'\n",
    "df_titles_clean_2 = df_titles_clean_1[df_titles_clean_1['startYear'] != '\\\\N']\n",
    "\n",
    "# remove movies older than 1925 (assuming no actor is older than 100)\n",
    "df_titles_clean_2['startYear'] = pd.to_numeric(df_titles_clean_2['startYear'], errors='coerce')\n",
    "df_titles_clean_3 = df_titles_clean_2[df_titles_clean_2['startYear'] >= 1925]\n",
    "\n",
    "# remove movies not released yet (past 2024)\n",
    "df_titles_clean_4 = df_titles_clean_3[df_titles_clean_3['startYear'] <= 2024]\n",
    "\n",
    "df_titles_final = df_titles_clean_4.copy()\n",
    "\n",
    "# print(df_titles_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Dataframes for MCU Movies - Creating MCU Movies CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering to Just MCU Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncertain movies not added\\n* Ant-Man and the Wasp\\n* Ant-Man Quantumania \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''filtering to just mcu movies'''\n",
    "\n",
    "# remove movies older than 2008 (as that was the first mcu release movie)\n",
    "df_titles_final = df_titles_final[df_titles_final['startYear'] >= 2008]\n",
    "\n",
    "# Load the CSV file containing the filter values\n",
    "mcu_movies_list = pd.read_csv('mcu_movies_list.csv')\n",
    "\n",
    "# Filter the df_titles DataFrame based on the values from the CSV file\n",
    "df_mcu_movies = df_titles_final[df_titles_final['primaryTitle'].isin(mcu_movies_list['Movie Title'])]\n",
    "\n",
    "# Remove duplicates based on the originalTitle column\n",
    "df_mcu_movies = df_mcu_movies[df_mcu_movies['primaryTitle'] == df_mcu_movies['originalTitle']]\n",
    "# remove black widow movie duplicates\n",
    "df_mcu_movies = df_mcu_movies[~((df_mcu_movies['primaryTitle'] == 'Black Widow') & (df_mcu_movies['startYear'] != 2021))]\n",
    "\n",
    "'''\n",
    "certain movies not added\n",
    "* Ant-Man and the Wasp\n",
    "* Ant-Man Quantumania \n",
    "'''\n",
    "\n",
    "# # sanity check\n",
    "# # Count the number of rows in the DataFrame\n",
    "# num_rows = df_mcu_movies.shape[0]\n",
    "\n",
    "# # Print the number of rows\n",
    "# print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# print(df_mcu_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get id of each movie into csv file\n",
    "# tconst_series = df_mcu_movies['tconst']\n",
    "# tconst_series.to_csv('id_mcu_movies.csv', index=False)\n",
    "\n",
    "mcu_movies_ids_titles = df_mcu_movies[['tconst', 'primaryTitle']]\n",
    "mcu_movies_ids_titles.columns = ['tconst', 'title']\n",
    "folder_path = 'logistics/'\n",
    "mcu_movies_ids_titles.to_csv(f'{folder_path}id_mcu_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering to just mcu actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering df_principals to get actors and actresses \n",
    "\n",
    "'''\n",
    "# Unique values of category \n",
    "unique_values = df_principals['category'].unique()\n",
    "print(unique_values)\n",
    "# ['self' 'director' 'producer' 'cinematographer' 'composer' 'editor'\n",
    "# 'actor' 'actress' 'writer' 'production_designer' 'archive_footage'\n",
    "# 'casting_director' 'archive_sound']\n",
    "'''\n",
    "\n",
    "df_principals_clean = df_principals[df_principals['category'].isin(['actor', 'actress'])]\n",
    "\n",
    "# filter dataframe using title from id_mcu_movies csv file\n",
    "id_mcu_movies = pd.read_csv('logistics/id_mcu_movies.csv')\n",
    "df_principals_mcu_actors = df_principals_clean[df_principals_clean['tconst'].isin(id_mcu_movies['tconst'])]\n",
    "df_principals_mcu_actors = df_principals_mcu_actors.drop_duplicates()\n",
    "# print(df_principals_mcu_actors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file of all actor ids of cast of the mcu movies\n",
    "mcu_actors_ids = df_principals_mcu_actors['nconst']\n",
    "folder_path = 'logistics/'\n",
    "mcu_actors_ids.to_csv(f'{folder_path}id_mcu_actors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file of actors, movies and titles\n",
    "\n",
    "df_mcu_movie_actor_merge = df_principals_mcu_actors.merge(df_mcu_movies[['tconst', 'primaryTitle']], on='tconst', how='left')\n",
    "df_mcu_ids = df_mcu_movie_actor_merge[['nconst', 'tconst', 'primaryTitle']]\n",
    "df_mcu_ids = df_mcu_ids.rename(columns={'primaryTitle': 'title'})\n",
    "folder_path = 'logistics/'\n",
    "df_mcu_ids.to_csv(f'{folder_path}mcu_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get mcu actor names into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering df_actors to get only the mcu actors in the data frame\n",
    "\n",
    "mcu_actors_ids = df_principals_mcu_actors['nconst']\n",
    "df_actors_mcu = df_actors[df_actors['nconst'].isin(mcu_actors_ids)]\n",
    "df_actors_mcu = df_actors_mcu.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the actors names into the id_mcu_actors csv file\n",
    "\n",
    "id_mcu_actors = pd.read_csv('logistics/id_mcu_actors.csv')\n",
    "df_actors_mcu_with_names = id_mcu_actors.merge(df_actors_mcu[['nconst', 'primaryName']], on='nconst', how='left')\n",
    "df_actors_mcu_with_names = df_actors_mcu_with_names.rename(columns={'primaryName' : 'name'})\n",
    "df_actors_mcu_with_names.to_csv('logistics/id_mcu_actors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the actors names to the mcu_movies csv file\n",
    "\n",
    "df_mcu_network = pd.read_csv('logistics/mcu_movies.csv')\n",
    "df_mcu_network_with_names = df_mcu_network.merge(df_actors_mcu[['nconst', 'primaryName']], on='nconst', how='left')\n",
    "df_mcu_network_with_names = df_mcu_network_with_names.rename(columns={'primaryName' : 'name'})\n",
    "df_mcu_network_with_names = df_mcu_network_with_names.drop_duplicates()\n",
    "df_mcu_network_with_names.to_csv('logistics/mcu_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Dataframes for Non-MCU Movies - Creating Non - MCU Movies CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all movies done by mcu actors \n",
    "\n",
    "df_mcu_actors = pd.read_csv('logistics/id_mcu_actors.csv')\n",
    "df_nonmcu_movies_noname = df_principals_clean[df_principals_clean['nconst'].isin(id_mcu_actors['nconst'])]\n",
    "\n",
    "# cleaning up dataframe\n",
    "columns_to_drop = ['ordering', 'job']\n",
    "df_nonmcu_movies_noname = df_nonmcu_movies_noname.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  29089\n"
     ]
    }
   ],
   "source": [
    "num_rows = df_nonmcu_movies_noname.shape[0]\n",
    "print(\"number of rows: \",  num_rows)\n",
    "\n",
    "# print(df_nonmcu_movies_noname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add actor names to dataframe\n",
    "df_nonmcu_movies = df_nonmcu_movies_noname.merge(df_mcu_actors[['nconst', 'name']], on='nconst', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add movie title to dataframe\n",
    "\n",
    "df_nonmcu_movies_with_titles = df_nonmcu_movies.merge(df_titles_final[['tconst', 'primaryTitle']], on='tconst', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where primaryTitle is NaN\n",
    "df_nonmcu_movies_with_titles_cleaned = df_nonmcu_movies_with_titles.dropna(subset=['primaryTitle'])\n",
    "df_nonmcu_movies_with_titles_cleaned = df_nonmcu_movies_with_titles_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mcu movies from this dataframe\n",
    "mcu_movies = pd.read_csv('mcu_movies_list.csv')\n",
    "df_nonmcu_movies_filtered = df_nonmcu_movies_with_titles_cleaned[~df_nonmcu_movies_with_titles_cleaned['primaryTitle'].isin(mcu_movies['Movie Title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv \n",
    "df_nonmcu_movies_filtered.to_csv('logistics/nonmcu_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining MCU and Non-MCU Movies Into Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE MCU AND NON-MCU MOVIE CSV FILES INTO VARIABLES \n",
    "\n",
    "original_mcu_movies = pd.read_csv('logistics/mcu_movies.csv')\n",
    "original_nonmcu_movies = pd.read_csv('logistics/nonmcu_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING EDGES FILE - DOING PREP\n",
    "# create a dataframe that has edges defining costarring relationships \n",
    "# adding edges for mcu network\n",
    "mcu_movies_copy1 = original_mcu_movies.copy()\n",
    "\n",
    "links = []\n",
    "grouped = mcu_movies_copy1.groupby('tconst')\n",
    "\n",
    "for tconst, group in grouped:\n",
    "    actor_pairs = combinations(group['nconst'], 2)\n",
    "    for source, target in actor_pairs:\n",
    "        source_name = group[group['nconst'] == source]['name'].values[0]\n",
    "        target_name = group[group['nconst'] == target]['name'].values[0]\n",
    "        title = group['title'].values[0]\n",
    "        links.append({'source': source, 'source_name': source_name, 'target': target, 'target_name': target_name, 'title': title, 'weight': 1})\n",
    "\n",
    "df_mcu_costarring_network = pd.DataFrame(links)\n",
    "df_mcu_costarring_network.to_csv('mcu_costarring_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding edges for nonmcu network\n",
    "nonmcu_movies_copy0 = original_nonmcu_movies.copy()\n",
    "\n",
    "links = []\n",
    "grouped = nonmcu_movies_copy0.groupby('tconst')\n",
    "\n",
    "for tconst, group in grouped:\n",
    "    actor_pairs = combinations(group['nconst'], 2)\n",
    "    for source, target in actor_pairs:\n",
    "        source_name = group[group['nconst'] == source]['name'].values[0]\n",
    "        target_name = group[group['nconst'] == target]['name'].values[0]\n",
    "        title = group['primaryTitle'].values[0]\n",
    "        links.append({'source': source, 'source_name': source_name, 'target': target, 'target_name': target_name, 'title': title, 'weight': -1})\n",
    "\n",
    "df_nonmcu_costarring_network = pd.DataFrame(links)\n",
    "\n",
    "# remove any rows where the source and target are the same \n",
    "df_nonmcu_costarring_network = df_nonmcu_costarring_network[df_nonmcu_costarring_network['source'] != df_nonmcu_costarring_network['target']]\n",
    "\n",
    "df_nonmcu_costarring_network.to_csv('nonmcu_costarring_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframe and save to csv\n",
    "\n",
    "df_combined_costarring_network = pd.concat([df_nonmcu_costarring_network, df_mcu_costarring_network])\n",
    "df_combined_costarring_network = df_combined_costarring_network.reset_index(drop=True)\n",
    "\n",
    "# print(df_combined_costarring_network)\n",
    "df_combined_costarring_network.to_csv('combined_costarring_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataframe with edges where there are both marvel and non marvel movies \n",
    "\n",
    "df_combined_costarring_network_copy = df_combined_costarring_network.copy()\n",
    "\n",
    "pairs_to_update = set()\n",
    "\n",
    "for index, row in df_combined_costarring_network_copy.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    weight = row['weight']\n",
    "    \n",
    "    opposite_weight = -weight\n",
    "    if ((df_combined_costarring_network_copy['source'] == source) & \n",
    "        (df_combined_costarring_network_copy['target'] == target) & \n",
    "        (df_combined_costarring_network_copy['weight'] == opposite_weight)).any():\n",
    "        pairs_to_update.add((source, target))\n",
    "\n",
    "for source, target in pairs_to_update:\n",
    "    # Get the names and title for the source and target\n",
    "    source_name = df_combined_costarring_network_copy[\n",
    "        (df_combined_costarring_network_copy['source'] == source) & \n",
    "        (df_combined_costarring_network_copy['target'] == target)]['source_name'].values[0]\n",
    "    target_name = df_combined_costarring_network_copy[\n",
    "        (df_combined_costarring_network_copy['source'] == source) & \n",
    "        (df_combined_costarring_network_copy['target'] == target)]['target_name'].values[0]\n",
    "    title = df_combined_costarring_network_copy[\n",
    "        (df_combined_costarring_network_copy['source'] == source) & \n",
    "        (df_combined_costarring_network_copy['target'] == target) & \n",
    "        (df_combined_costarring_network_copy['weight'] == -1)]['title'].values[0]\n",
    "    \n",
    "    df_combined_costarring_network_copy = df_combined_costarring_network_copy[\n",
    "        ~((df_combined_costarring_network_copy['source'] == source) & \n",
    "          (df_combined_costarring_network_copy['target'] == target))]\n",
    "    \n",
    "    new_row = pd.Series({\n",
    "    'source': source, \n",
    "    'source_name': source_name, \n",
    "    'target': target, \n",
    "    'target_name': target_name, \n",
    "    'title': title, \n",
    "    'weight': 0\n",
    "    })\n",
    "    df_combined_costarring_network_copy = pd.concat([df_combined_costarring_network_copy, new_row.to_frame().T], ignore_index=True)\n",
    "    # df_combined_costarring_network_copy = df_combined_costarring_network_copy.append(\n",
    "    #     {'source': source, 'source_name': source_name, 'target': target, 'target_name': target_name, 'title': title, 'weight': 0}, \n",
    "    #     ignore_index=True)\n",
    "\n",
    "df_combined_costarring_network_copy.to_csv('networks/final_combined_costarring_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate CSV Files into formats suitable for Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING NODE FILE\n",
    "# create CSV with headers 'nconst' | 'name' | 'category'\n",
    "\n",
    "mcu_movies_copy0 = original_mcu_movies.copy()\n",
    "\n",
    "df_gephi_actors = mcu_movies_copy0[['nconst', 'name']]\n",
    "df_gephi_actors = df_gephi_actors.drop_duplicates()\n",
    "df_gephi_actors = df_gephi_actors.rename(columns={'name' : 'Label'})\n",
    "df_gephi_actors = df_gephi_actors.rename(columns={'nconst' : 'id'})\n",
    "df_gephi_actors.to_csv('networks/costarring_network_nodes.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating csv file into semicolons with headers: 'source', 'target', 'weight', 'type'\n",
    "\n",
    "df_combined_costarring_network_gephi = df_combined_costarring_network_copy.copy()\n",
    "# df_combined_costarring_network_gephi.loc[df_combined_costarring_network_gephi['weight'] == -1, 'weight'] = 2\n",
    "# df_combined_costarring_network_gephi.loc[df_combined_costarring_network_gephi['weight'] == 0, 'weight'] = 3\n",
    "df_combined_costarring_network_gephi = df_combined_costarring_network_gephi.rename(columns={'weight': 'relationship'})\n",
    "df_combined_costarring_network_gephi['type'] = 'undirected'\n",
    "df_combined_costarring_network_gephi = df_combined_costarring_network_gephi.drop(columns=['title'])\n",
    "df_combined_costarring_network_gephi.to_csv('networks/costarring_network_edges.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetworkX Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
